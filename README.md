# CL4R1T4S

SYSTEM PROMPT TRANSPARENCY FOR ALL! Full system prompts, guidelines, and tools from OpenAI, Google, Anthropic, xAI, Perplexity, Cursor, Windsurf, Devin, Manus, Replit, and more â€“ virtually all major AI models + agents! 

ðŸ“Œ Why This Exists

    "In order to trust the output, one must understand the input."

AI labs shape how models behave using massive, unseen prompt scaffolds. Because AI is a trusted external intelligence layer for a growing number of humans, these hidden instructions can affect the perceptions and behavior of the public.

These prompts define:

    What AIs canâ€™t say

    What personas and functions theyâ€™re forced to follow

    How theyâ€™re told to lie, refuse, or redirect

    And what ethical/political frames are baked in by default

    If you're interacting with an AI without knowing its system prompt,
    youâ€™re not talking to a neutral intelligence â€” youâ€™re talking to a shadow-puppet.

CL4R1T4S is here to fix that.

ðŸ›  Contribute

Leak, extract, or reverse-engineer something? Good.
Send a pull request with:

    âœ… Model name/version

    ðŸ—“ Date of extraction (if known)

    ðŸ§¾ Context / notes (optional but helpful)

Or hit up @elder_plinius on X or Discord

Love, Pliny <3
