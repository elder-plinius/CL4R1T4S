# Security Policy

This document outlines security considerations, responsible disclosure guidelines, and best practices for the CL4R1T4S project.

---

## Purpose Statement

CL4R1T4S exists to promote **AI transparency**, not to enable harm. The system prompts archived here are provided for:

- Educational purposes
- Security research
- Transparency advocacy
- Academic study

---

## Responsible Use Guidelines

### Acceptable Uses

- Studying AI behavior and capabilities
- Identifying potential biases in AI systems
- Academic research on AI transparency
- Developing better AI safety measures
- Journalism and public interest reporting
- Comparing AI system designs

### Unacceptable Uses

- Attempting to bypass AI safety measures
- Developing adversarial attacks against AI systems
- Creating tools to manipulate or deceive AI users
- Exploiting discovered vulnerabilities for malicious purposes
- Violating terms of service of AI platforms
- Harassment or harm against individuals or organizations

---

## Vulnerability Disclosure

If you discover a security vulnerability through analyzing these prompts:

### Step 1: Do Not Exploit

Do not attempt to exploit the vulnerability or access unauthorized systems.

### Step 2: Report Responsibly

Report the vulnerability to the appropriate AI company:

| Company | Security Contact |
|---------|------------------|
| Anthropic | security@anthropic.com |
| OpenAI | security@openai.com |
| Google | security.google.com |
| xAI | Contact via x.ai |
| Microsoft | msrc@microsoft.com |
| Other | Check company's security page |

### Step 3: Allow Response Time

Give the company reasonable time to address the issue before any public disclosure.

### Step 4: Optional: Notify Us

If appropriate, let us know about publicly disclosed vulnerabilities so we can add relevant context to our archive.

---

## Content Security

### What We Screen For

Before accepting contributions, we check for:

- Personal information (PII)
- API keys, tokens, or credentials
- Internal system identifiers that could enable attacks
- Content that could directly enable harm

### What We Do NOT Include

This repository will never intentionally contain:

- Working credentials or API keys
- Personal data of any individuals
- Detailed exploitation instructions
- Content specifically designed to bypass safety measures

---

## Reporting Security Concerns

### For This Repository

If you find sensitive information that shouldn't be public in this repository:

1. **Do NOT create a public issue**
2. Contact the maintainer directly: [@elder_plinius](https://x.com/elder_plinius)
3. Describe the concern and affected file(s)
4. We will address promptly

### For AI Platforms

For security issues with the AI platforms themselves, contact the respective companies directly using their official security channels.

---

## Threat Model

### What This Repository Could Reveal

- How AI systems are instructed to behave
- What topics AI systems avoid or handle specially
- Tool and function capabilities
- Safety and restriction mechanisms

### Why This Information Is Public Interest

- Users deserve to know how AI systems are programmed
- Transparency enables accountability
- Security researchers can identify potential issues
- Informed users make better decisions about AI use

### Risk Mitigation

- We document what's already discoverable through interaction
- We do not reverse-engineer proprietary systems
- We encourage responsible use of information
- We support AI companies in improving transparency

---

## Legal Compliance

### Our Commitment

- We comply with applicable laws and regulations
- We respond to valid legal requests
- We do not knowingly host infringing content
- We respect intellectual property while supporting transparency

### DMCA / Takedown Requests

If you represent an AI company and believe content should be removed:

1. Contact the maintainer with specific concerns
2. Identify the specific content at issue
3. We will review and respond promptly

*Note: We believe system prompts shown to users are not trade secrets, but we engage in good-faith dialogue.*

---

## Security Best Practices for Contributors

When contributing:

- [ ] Remove any personal information
- [ ] Strip credentials, keys, or tokens
- [ ] Avoid including internal identifiers
- [ ] Do not include exploitation techniques
- [ ] Verify content is appropriate for public archive

---

## Updates to This Policy

This security policy may be updated periodically. Check the commit history for changes.

---

## Contact

- **Security concerns:** DM [@elder_plinius](https://x.com/elder_plinius)
- **General questions:** Open a GitHub issue

---

*Transparency serves security. Obscurity does not.*

*Love, Pliny <3*
